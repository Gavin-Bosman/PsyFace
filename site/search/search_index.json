{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<ul> <li> <p>Overview </p> <p>PyFAME is a python package for dynamic facial occlusion and facial color manipulation in both still images and videos. PyFAME provides a range of tools for manipulating color in user-specified facial regions using industry-standard color spaces (1) (RGB, BGR, HSV, CIELAB), as well as dynamic facial occlusion of user-specified facial regions, and facial (as well as individual facial regions) isolation from the background using video matting.</p> <p>PyFAME was designed with ease of processing in mind. Each of the core package functions can process entire directories of mixed image and video files, with or without nested directories, from a single function call. Uniquely, PyFAME provides access to temporal color manipulation over videos. Users can chooses from a variety of predefined timing functions (2) or choose to define their own. </p> <ol> <li> For more information on color spaces check out Cambridge in Color. </li> <li> PyFAME provides predefined function definitions for linear, sigmoid, gaussian and sinusoidal functions.</li> </ol> </li> <li> <p>Function Outputs</p> <p></p> </li> </ul>"},{"location":"#pyfame","title":"PyFAME","text":"<p>View On Github  Open Documentation </p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":"<ul> <li>v0.5... unit testing</li> <li>v1.0 gui preview prior to file processing</li> </ul>"},{"location":"changelog/#056-2024-11-12","title":"[0.5.6] - 2024-11-12","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Bug fixes for last major feature update (v0.5.5).</li> <li><code>CHIN_PATH</code> has been added as a predefined path for use with all facial manipulation functions.</li> <li><code>extract_color_channel_means</code> has been renamed as <code>extract_face_color_means</code>. The function now will not only output full-facial means, but also regional color means in the cheek, nose and chin areas for all colour spaces. </li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>The Hemi-face family of landmark paths have been converted to standard paths, and no longer require in-place computation. </li> <li><code>occlude_face_region</code>'s implementation of bar-style occlusion has been reworked, such that now the occluding bar will track correctly with the position of the face and axis of the head (the occluding bar no longer remains paralell to the horizontal axis).</li> <li><code>face_color_shift</code>, <code>face_saturation_shift</code> and <code>face_brightness_shift</code> now only take list[list[tuple]] for input parameter <code>landmark_regions</code>. This massively reduces the ammount of duplicate code previously divided among if-else statements based on what was passed to <code>landmark_regions</code>.</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":""},{"location":"changelog/#053-055-2024-10-16","title":"[0.5.3 - 0.5.5] - 2024-10-16","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Major feature updates to all facial manipulation functions. <code>face_color_shift</code>, <code>face_saturation_shift</code>, <code>face_brightness_shift</code> and <code>blur_face_region</code> now are all compatible with timing functions, and every predefined landmark region defined within <code>psyfaceutils.py</code>. </li> <li>Some of the landmark paths have been redefined as placeholders, as they either need to be calculated in place (hemi-face regions) or require a different method to draw the landmark polygons (Cheek landmark regions form concave polygons).</li> <li><code>FACE_SKIN_PATH</code> constant has been defined in order to provided easier access to facial skin colouring, leaving the lips and eyes untouched. For similar ease of use reasons, other commonly used grouped regions have been defined, including <code>CHEEKS_PATH</code> and <code>CHEEKS_NOSE_PATH</code> for use in facial \"blushing\".</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":""},{"location":"changelog/#removed_1","title":"Removed","text":"<ul> <li>Bad practice global variable declarations have been removed entirely. </li> </ul>"},{"location":"changelog/#052-2024-10-09","title":"[0.5.2] - 2024-10-09","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li><code>Occlude_face_region</code> can now perform vertical and horizontal hemi-face occlusion. Hemi-face masks rely on the facial screen coords, thus they cannot be precomputed. However, predefined placeholder constants <code>HEMI_FACE_TOP</code>, <code>HEMI_FACE_BOTTOM</code>, <code>HEMI_FACE_LEFT</code>, and <code>HEMI_FACE_RIGHT</code> have been defined and can still be passed in <code>landmarks_to_occlude</code> as any of the other predefined landmark paths can. </li> <li>Helper function <code>compute_line_intersection</code> has been created and can be found in <code>psyfaceutils.py</code>.</li> <li>Additional masking option <code>EYES_NOSE_MOUTH_MASK</code> has been added to <code>mask_face_region</code>.</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":""},{"location":"changelog/#removed_2","title":"Removed","text":"<ul> <li>Predefined landmark paths <code>UPPER_FACE_PATH</code> and <code>LOWER_FACE_PATH</code> have been removed, and replaced with <code>HEMI_FACE_TOP</code>, and <code>HEMI_FACE_BOTTOM</code> respectively.</li> </ul>"},{"location":"changelog/#051-2024-10-03","title":"[0.5.1] - 2024-10-03","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li><code>Blur_face_region</code> provides dynamic facial blurring functionality with several blurring methods (average, gaussian, median) over user-specified facial regions. </li> <li>Added horizontal hemi-face occlusion, <code>UPPER_FACE_PATH</code> and <code>LOWER_FACE_PATH</code> constants can be found in psyfaceutils.py.</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li><code>Face_luminance_shift</code> has been replaced with <code>face_brightness_shift</code>. <code>Face_brightness_shift</code> will now take an integer shift value in the range [-255, 255], with -255 and 255 representing pure black and white respectively. </li> </ul>"},{"location":"changelog/#removed_3","title":"Removed","text":"<ul> <li><code>Face_luminance_shift</code> has been removed due to buggy behaviour when manipulating image luminance.</li> </ul>"},{"location":"changelog/#050-2024-09-24","title":"[0.5.0] - 2024-09-24","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Package documentation is now built with MKDocs</li> <li><code>Face_saturation_shift</code> and <code>Face_luminance_shift</code> are now standalone functions, where previously saturation and luma parameters were passed to the Face_color_shift function. </li> <li>Github.io hosting for documentation page, as well as refactored github landing page and readme.md.</li> <li>License.txt added to root project structure.</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li><code>Shift_color_temp</code> was refactored to be a nested function within <code>Face_color_shift</code>, saturation and luminance shifting were relocated to their own specific functions. </li> <li>Floodfilling operation involved with foreground-background seperation had some buggy behaviour if there was any discontinuity in the background. An intermediate step was added where prior to floodfilling, the thresholded image is padded with a 10 pixel border, which is removed after the floodfill. This border ensures background continuity when performing the floodfill operation.</li> <li>Parameters <code>max_color_shift</code> and <code>max_sat_shift</code> are now renamed to <code>shift_magnitude</code>.</li> </ul>"},{"location":"changelog/#removed_4","title":"Removed","text":"<ul> <li>Sphinx and readthedocs project files and dependencies</li> </ul>"},{"location":"changelog/#042-2024-08-24","title":"[0.4.2] - 2024-08-24","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Sphinx dependency for autodocumentation.</li> <li>Rst files defining the documentation build. </li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>Updated readme.md with examples, licenses and link to documentation page</li> </ul>"},{"location":"changelog/#removed_5","title":"Removed","text":""},{"location":"changelog/#041-2024-08-18","title":"[0.4.1] - 2024-08-18","text":""},{"location":"changelog/#added_6","title":"Added","text":""},{"location":"changelog/#changed_6","title":"Changed","text":"<ul> <li>v0.4.1 bug fixes for processing directories of mixed file types (images and videos). </li> </ul>"},{"location":"changelog/#removed_6","title":"Removed","text":""},{"location":"changelog/#040-2024-08-17","title":"[0.4.0] - 2024-08-17","text":""},{"location":"changelog/#added_7","title":"Added","text":""},{"location":"changelog/#changed_7","title":"Changed","text":"<ul> <li>v0.4 Refactored all methods; moved repetative frame operations to nested functions for increased readability.</li> <li>Fixed buggy behaviour when working with still images over all methods. On top of video formats .MP4 and .MOV, you can now perform facial masking, occlusion and colour shifting over image formats .jpg, .jpeg, .png, and .bmp.</li> <li>Increased error handling; methods should now be able to process large directories of mixed file formats efficiently in a single call. </li> </ul>"},{"location":"changelog/#removed_7","title":"Removed","text":""},{"location":"changelog/#031-2024-08-11","title":"[0.3.1] - 2024-08-11","text":""},{"location":"changelog/#added_8","title":"Added","text":"<ul> <li>v0.3.1 Support for nose masking and occluding</li> </ul>"},{"location":"changelog/#changed_8","title":"Changed","text":"<ul> <li>Added bar-style occlusion options to occlude_face_region(). You can now perform bar-style occlusion on the eyes, nose  and mouth regions. </li> </ul>"},{"location":"changelog/#removed_8","title":"Removed","text":""},{"location":"changelog/#030-2024-08-02","title":"[0.3.0] - 2024-08-02","text":""},{"location":"changelog/#added_9","title":"Added","text":"<ul> <li>v0.3 occlude_face_region()</li> </ul>"},{"location":"changelog/#changed_9","title":"Changed","text":"<ul> <li>Redefined the naming convention used for constants in utils.py</li> </ul>"},{"location":"changelog/#removed_9","title":"Removed","text":""},{"location":"changelog/#022-2024-07-31","title":"[0.2.2] - 2024-07-31","text":""},{"location":"changelog/#added_10","title":"Added","text":""},{"location":"changelog/#changed_10","title":"Changed","text":"<ul> <li>Changed mp4 video codec from h264 to cv2 supported mp4v.</li> <li>Mask_face_region and face_color_shift now take confidence parameters for the underlying mediapipe face landmarker model.</li> <li>Implemented otsu thresholding to isolate foreground to use as a mask. This foreground mask ensures that no background  artifacts are present in the facial color shifting, or facial masking. </li> <li>Added documentation for new function parameters.</li> </ul>"},{"location":"changelog/#removed_10","title":"Removed","text":""},{"location":"changelog/#021-2024-07-24","title":"[0.2.1] - 2024-07-24","text":""},{"location":"changelog/#added_11","title":"Added","text":"<ul> <li>v0.2.1 transcode_video_to_mp4()</li> </ul>"},{"location":"changelog/#changed_11","title":"Changed","text":"<ul> <li>All functions will work by default with .mp4 and .mov video files. If an older container is being used,  see transcode_video_to_mp4 to convert video codecs.</li> <li>Bug fixes with facial mask in face_color_shift; removed background artifacts present in the masked facial region.</li> </ul>"},{"location":"changelog/#removed_11","title":"Removed","text":"<ul> <li>Removed dependancy ffprobe-python.</li> </ul>"},{"location":"changelog/#020-2024-07-21","title":"[0.2.0] - 2024-07-21","text":""},{"location":"changelog/#added_12","title":"Added","text":"<ul> <li>v0.2 added dependancy ffprobe-python.</li> </ul>"},{"location":"changelog/#changed_12","title":"Changed","text":"<ul> <li>Added input file codec sniffing, output video files will now match input type for mask_face_region and face_color_shift.</li> </ul>"},{"location":"changelog/#removed_12","title":"Removed","text":""},{"location":"changelog/#011-2024-07-20","title":"[0.1.1] - 2024-07-20","text":""},{"location":"changelog/#added_13","title":"Added","text":""},{"location":"changelog/#changed_13","title":"Changed","text":"<ul> <li>Minor bug fix for negative saturation shift.</li> </ul>"},{"location":"changelog/#removed_13","title":"Removed","text":""},{"location":"changelog/#010-2024-07-17","title":"[0.1.0] - 2024-07-17","text":""},{"location":"changelog/#added_14","title":"Added","text":"<ul> <li>v0.1 mask_face_region()</li> <li>v0.1 extract_color_channel_means()</li> <li>v0.1 face_color_shift()</li> <li>v0.1 shift_color_temp()</li> </ul>"},{"location":"changelog/#changed_14","title":"Changed","text":"<ul> <li>Updated documentation and type hints for all package functions.</li> <li>Vectorized color shifting operations in shift_color_temp, massively reducing time costs.</li> <li>Restructured package into src, data and testing folders.</li> <li>Moved constants and helper functions into utils.py.</li> </ul>"},{"location":"changelog/#removed_14","title":"Removed","text":""},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) [2024] [Gavin Bosman]</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#facial-masking","title":"Facial Masking","text":"<p><code>mask_face_region</code> will apply the specified <code>mask_type</code> to all files contained in <code>input_dir</code>, outputting masked images and videos to <code>output_dir</code>\\Masked_Video_Output.</p> <pre><code>def mask_face_region(input_dir:str, output_dir:str, mask_type:int = FACE_SKIN_ISOLATION, with_sub_dirs:bool = False,\n                min_detection_confidence:float = 0.5, min_tracking_confidence:float = 0.5, static_image_mode:bool = False) -&gt; None:\n</code></pre> Parameter Type Description <code>input_dir</code> <code>str</code> A path string to the directory containing files to process. <code>output_dir</code> <code>str</code> A path string to the directory where processed files will be output. <code>mask_type</code> <code>int</code> An integer flag specifying the type of masking operation being performed. One of <code>FACE_OVAL</code>, <code>FACE_OVAL_TIGHT</code> OR <code>FACE_SKIN_ISOLATION</code>. <code>with_sub_dirs</code> <code>bool</code> A boolean flag indicating if the input directory contains sub-directories. <code>min_detection_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model. <code>min_tracking_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model. <code>static_image_mode</code> <code>bool</code> A boolean flag indicating that the current filetype is static images. Info <p>Parameters <code>min_detection_confidence</code>, <code>min_tracking_confidence</code>, and <code>static_image_mode</code> are passed directly to the declaration of the MediaPipe FaceMesh model. </p> <pre><code>import mediapipe as mp\n\nface_mesh = mp.solutions.face_mesh.FaceMesh(max_num_faces = 1, min_detection_confidence = min_detection_confidence,\n                                    min_tracking_confidence = min_tracking_confidence, static_image_mode = static_image_mode)\n</code></pre> <p>For more information on MediaPipes FaceMesh solution, see here.</p>"},{"location":"reference/#dynamic-facial-occlusion","title":"Dynamic Facial Occlusion","text":"<p><code>occlude_face_region</code> takes the landmark regions specified within <code>landmarks_to_occlude</code>, and occludes them with the specified method for each image or video file present within the input directory provided in <code>input_dir</code>. Processed videos will be written to <code>output_dir</code>\\Occluded_Video_Output.</p> <pre><code>def occlude_face_region(input_dir:str, output_dir:str, landmarks_to_occlude:list[list[tuple]] | list[tuple], \n    occlusion_fill:int = OCCLUSION_FILL_BLACK, with_sub_dirs:bool =  False, min_detection_confidence:float = 0.5, min_tracking_confidence:float = 0.5, static_image_mode:bool = False) -&gt; None:\n</code></pre> Parameter Type Description <code>input_dir</code> <code>str</code> A path string to the directory containing files to process. <code>output_dir</code> <code>str</code> A path string to the directory where processed files will be output. <code>landmarks_to_occlude</code> <code>list[list] or list[tuple]</code> One or more lists of facial landmark paths. These paths can be manually created using <code>psyfaceutils.create_path()</code>, or you may use any of the library provided predefined landmark paths. <code>occlusion_fill</code> <code>int</code> An integer flag indicating the occlusion method to be used. One of <code>OCCLUSION_FILL_BLACK</code>, <code>OCCLUSION_FILL_MEAN</code> or <code>OCCLUSION_FILL_BAR</code>. <code>with_sub_dirs</code> <code>bool</code> A boolean flag indicating if the input directory contains sub-directories. <code>min_detection_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model. <code>min_tracking_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model. <code>static_image_mode</code> <code>bool</code> A boolean flag indicating that the current filetype is static images."},{"location":"reference/#facial-colour-shifting","title":"Facial Colour Shifting","text":""},{"location":"reference/#face_color_shift","title":"face_color_shift( )","text":"<p><code>face_color_shift</code> performs a weighted color shift on the color channel specified in <code>shift_color</code>, weighted by the outputs of the provided <code>timing_func</code>. Parameters <code>onset_t</code> and <code>offset_t</code> can be used to specify when the color shifting fades in and fades out (this only applies to video files). <code>face_color_shift</code> makes use of the CIELAB color space to perform color shifting, due to it being far more perceptually uniform than the standard RGB or BGR color spaces.</p> Note <p><code>face_color_shift</code> requires the outputs of the provided <code>timing_func</code> to be normalised; that is, in the range [0,1]. Predefined normalised functions such as <code>sigmoid</code>, <code>linear</code> and <code>gaussian</code> are available for use in <code>psyfaceutils</code>. Extra parameters for these functions can be passed to <code>face_color_shift</code> as keyword arguments. Users may also define their own timing functions, but it is up to the user to ensure their functions take at least one input float parameter, and that the return value is within the normal range.</p> <pre><code>def face_color_shift(input_dir:str, output_dir:str, onset_t:float = 0.0, offset_t:float = 0.0, shift_magnitude: float = 8.0, timing_func:Callable[...,float] = sigmoid, shift_color:str|int = COLOR_RED, with_sub_dirs:bool = False, \nmin_detection_confidence:float = 0.5, min_tracking_confidence:float = 0.5) -&gt; None: \n</code></pre> Parameter Type Description <code>input_dir</code> <code>str</code> A path string to the directory containing files to process. <code>output_dir</code> <code>str</code> A path string to the directory where processed files will be output. <code>onset_t</code> <code>float</code> The onset time when colour shifting will begin. <code>offset_t</code> <code>float</code> The offset time when colour shifting will begin to fade out. <code>shift_magnitude</code> <code>float</code> The maximum units to shift the specified colour channel by, during peak onset. <code>timing_func</code> <code>Callable[..., float]</code> Any function that takes at least one float, and returns a normalised float value. <code>shift_colour</code> <code>str, int</code> Either a string literal (i.e. \"red\"), or a predefined integer constant; one of <code>COLOR_RED</code>, <code>COLOR_BLUE</code>, <code>COLOR_GREEN</code> or <code>COLOR_YELLOW</code>. <code>with_sub_dirs</code> <code>bool</code> A boolean flag indicating if the input directory contains sub-directories. <code>min_detection_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model. <code>min_tracking_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model."},{"location":"reference/#face_saturation_shift","title":"face_saturation_shift( )","text":"<p><code>face_saturation_shift</code> performs a weighted saturation shift in a near identical manner to <code>face_color_shift</code> above. This function makes use of the HSV color space to manipulate saturation. </p> <pre><code>def face_saturation_shift(input_dir:str, output_dir:str, onset_t:float = 0.0, offset_t:float = 0.0, shift_magnitude:float = -8.0, \n                          timing_func:Callable[..., float] = sigmoid, with_sub_dirs:bool = False, min_detection_confidence:float = 0.5,\n                           min_tracking_confidence:float = 0.5) -&gt; None:\n</code></pre> Parameter Type Description <code>input_dir</code> <code>str</code> A path string to the directory containing files to process. <code>output_dir</code> <code>str</code> A path string to the directory where processed files will be output. <code>onset_t</code> <code>float</code> The onset time when colour shifting will begin. <code>offset_t</code> <code>float</code> The offset time when colour shifting will begin to fade out. <code>shift_magnitude</code> <code>float</code> The maximum units to shift the specified colour channel by, during peak onset. <code>timing_func</code> <code>Callable[..., float]</code> Any function that takes at least one float, and returns a normalised float value. <code>with_sub_dirs</code> <code>bool</code> A boolean flag indicating if the input directory contains sub-directories. <code>min_detection_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model. <code>min_tracking_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model."},{"location":"reference/#face_lightness_shift","title":"face_lightness_shift( )","text":"<p><code>face_lightness_shift</code> performs a weighted lightness shift in a near identical manner to <code>face_color_shift</code> above. Lightness, represented by the L in the CIELAB color space, is taken as the cube root of the relative luminosity. Lightness ranges from 0-100, with black being defined as 0, and pure white being defined as 100.</p> <p>Warning</p> <p>Lightness manipulation can cause unexpected behaviour when the initial lightness value is unknown. <code>face_lightness_shift</code> is currently experimental, so results may vary depending on the input files you are working with. Proceed with caution.</p> <pre><code>def face_lightness_shift(input_dir:str, output_dir:str, onset_t:float = 0.0, offset_t:float = 0.0, shift_magnitude:float = 10.0, \n                        timing_func:Callable[..., float] = sigmoid, with_sub_dirs:bool = False, min_detection_confidence:float = 0.5,\n                        min_tracking_confidence:float = 0.5) -&gt; None:\n</code></pre> Parameter Type Description <code>input_dir</code> <code>str</code> A path string to the directory containing files to process. <code>output_dir</code> <code>str</code> A path string to the directory where processed files will be output. <code>onset_t</code> <code>float</code> The onset time when colour shifting will begin. <code>offset_t</code> <code>float</code> The offset time when colour shifting will begin to fade out. <code>shift_magnitude</code> <code>float</code> The maximum units to shift the specified colour channel by, during peak onset. <code>timing_func</code> <code>Callable[..., float]</code> Any function that takes at least one float, and returns a normalised float value. <code>with_sub_dirs</code> <code>bool</code> A boolean flag indicating if the input directory contains sub-directories. <code>min_detection_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model. <code>min_tracking_confidence</code> <code>float</code> A confidence measure in the range [0,1], passed on to the MediaPipe FaceMesh model."}]}